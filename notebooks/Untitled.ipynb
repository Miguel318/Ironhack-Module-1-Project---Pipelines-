{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          worthChange millions USD      position             \n",
      "                                             count mean    count         mean\n",
      "country       worth BUSD                                                     \n",
      "Algeria       4                                  1  0.0        1   563.000000\n",
      "Angola        2                                  1  0.0        1   933.000000\n",
      "Argentina     1                                  1  0.0        1  1378.000000\n",
      "              3                                  1  0.0        1   796.000000\n",
      "Australia     1                                 11  0.0       11  1815.727273\n",
      "...                                            ...  ...      ...          ...\n",
      "United States 21                                 1  0.0        1    44.000000\n",
      "              23                                 1  0.0        1    34.000000\n",
      "              84                                 1  0.0        1     3.000000\n",
      "              90                                 1  0.0        1     2.000000\n",
      "Venezuela     1                                  1  0.0        1  2023.000000\n",
      "\n",
      "[183 rows x 4 columns]\n",
      "pollas\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import matplotlib.pylab as plt\n",
    "plt.rcdefaults()\n",
    "\n",
    "#IMPORT AND EXTRACT DATABASE:\n",
    "\n",
    "df = sqlite3.connect('/Users/MIGUEL/Desktop/CLAB1/Ironhack-Module-1-Project---Pipelines-/data/raw/Miguel318.db')\n",
    "dfBI = pd.read_sql_query(\"SELECT * FROM business_info\", df) \n",
    "dfRI = pd.read_sql_query(\"SELECT * FROM rank_info\", df)\n",
    "dfPI = pd.read_sql_query(\"SELECT * FROM personal_info\", df)\n",
    "\n",
    "#WRANGLING - DATA CLEANING - DATABASE:\n",
    "\n",
    "dfBI.drop(['realTimeWorth'], axis='columns', inplace=True)\n",
    "dfBI.drop(['Unnamed: 0'], axis='columns', inplace=True)\n",
    "dfBI.drop(['realTimePosition'], axis='columns', inplace=True)\n",
    "dfBI.replace({\"BUSD\": ' '})\n",
    "dfBI.worthChange.replace('na', '0.0', regex=True, inplace=True)\n",
    "dfBI.worth.replace('[BUSD]+$', '', regex=True, inplace=True)        \n",
    "dfBI.worthChange.replace('[millions USD]+$', '', regex=True, inplace=True)\n",
    "dfBI['worth'] = dfBI['worth'].astype('float').astype('int')\n",
    "dfBI['worthChange'] = dfBI['worthChange'].astype('float').astype('int')\n",
    "dfBI['id'] = dfBI['id'].astype('object').astype('int')\n",
    "dfBI = dfBI.rename(columns={'worth':'worth BUSD', 'worthChange':' worthChange millions USD'})\n",
    "dfBI = dfBI.drop_duplicates()\n",
    "dfBI = dfBI.reset_index(drop=True)\n",
    "dfRI.drop(['Unnamed: 0'], axis='columns', inplace=True)\n",
    "dfRI['position'] = dfRI['position'].fillna(0)   \n",
    "dfRI['position'] = dfRI['position'].astype('float').astype('int')\n",
    "dfRI = dfRI.apply(lambda x: x.astype(str).str.lower())\n",
    "dfRI['position'] = dfRI['position'].astype('object').astype('int')\n",
    "dfRI['id'] = dfRI['id'].astype('object').astype('int')\n",
    "dfRI = dfRI.drop(dfRI[dfRI['position']==0].index)\n",
    "dfRI = dfRI.reset_index(drop=True)\n",
    "dfPI.drop(['Unnamed: 0'], axis='columns', inplace=True)\n",
    "dfPI.drop(['lastName'], axis='columns', inplace=True)\n",
    "dfPI.gender.replace('[M]+$', 'Male', regex=True, inplace=True)\n",
    "dfPI.gender.replace('[F]+$', 'Female', regex=True, inplace=True)\n",
    "dfPI['gender'] = dfPI['gender'].astype('object').astype('str')\n",
    "dfPI.age.replace('[years old]+$', '', regex=True, inplace=True)   \n",
    "dfPI['age'] = dfPI['age'].fillna(0)   \n",
    "dfPI['age'] = dfPI['age'].astype('float').astype('int') \n",
    "\n",
    "now = datetime.now()\n",
    "now.year\n",
    "\n",
    "stats = dfPI.describe().T\n",
    "stats['IQR'] = stats['75%'] - stats['25%']\n",
    "\n",
    "\n",
    "outliers = pd.DataFrame(columns=dfPI.columns)\n",
    "\n",
    "for col in stats.index:\n",
    "    iqr = stats.at[col,'IQR']\n",
    "    cutoff = iqr * 1.5\n",
    "    lower = stats.at[col,'25%'] - cutoff\n",
    "    upper = stats.at[col,'75%'] + cutoff\n",
    "    results = dfPI[(dfPI[col] < lower) | \n",
    "            (dfPI[col] > upper)].copy()\n",
    "    results['Outlier'] = col\n",
    "    outliers = outliers.append(results)\n",
    "    'sort=False'\n",
    "\n",
    "dfPI['new_age'] = now.year - outliers['age']\n",
    "dfPI.new_age.fillna(dfPI.age, inplace=True)\n",
    "\n",
    "dfPI['age'] = dfPI['new_age']\n",
    "dfPI.drop(['new_age'], axis='columns', inplace=True)\n",
    "dfPI.age.replace(now.year, 'None', regex=True, inplace=True)\n",
    "dfPI = dfPI.drop_duplicates()\n",
    "dfPI = dfPI.reset_index(drop=True)\n",
    "\n",
    "#EXPORT CLEAN DATA TO LOCAL:\n",
    "        \n",
    "dfBI.to_csv('/Users/MIGUEL/Desktop/TestProject/dfBussinesInfoCLEAN.csv', index=False)\n",
    "dfRI.to_csv('/Users/MIGUEL/Desktop/TestProject/dfrankinfoCLEAN.csv', index=False)\n",
    "dfPI.to_csv('/Users/MIGUEL/Desktop/TestProject/dfPersonalInfoCLEAN.csv', index=False)\n",
    "\n",
    "#MERGE DATAFRAMES:\n",
    "\n",
    "df4 = pd.merge(dfBI, dfRI, on=['id', 'id'])\n",
    "df_total = pd.merge(df4, dfPI, on=['id', 'id'])\n",
    "\n",
    "df_total.drop(['id'], axis='columns', inplace=True)\n",
    "\n",
    "df_total.to_csv('/Users/MIGUEL/Desktop/TestProject/df_total.csv', index=False)\n",
    "\n",
    "#WEB - SCRAPPING:\n",
    "    #Extract URL - Scrapper:\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population'\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "table = soup.find_all('table',{'class':'wikitable sortable mw-datatable'})[0]\n",
    "table\n",
    "\n",
    "    # tr represent the table rows:\n",
    "rows = table.find_all('tr')\n",
    "rows_parsed = [row.text for row in rows]\n",
    "rows_parsed\n",
    "\n",
    "    #Parsering:\n",
    "\n",
    "def smart_parser(row_text):\n",
    "    row_text = row_text.replace('\\nPopulation\\n\\n\\n', '\\nPopulation\\n').strip('\\n')\n",
    "    row_text = row_text.replace('\\n\\n', '\\n').strip('\\n')\n",
    "    row_text = row_text.replace('\\nPopulation\\n% of World\\n', '\\nPopulation % of World\\n').strip('\\n')\n",
    "    row_text = re.sub('\\[\\d\\]', '', row_text)\n",
    "    \n",
    "    return list(map(lambda x: x.strip(), row_text.split('\\n')))\n",
    "\n",
    "well_parsed = list(map(lambda x: smart_parser(x), rows_parsed))\n",
    "\n",
    "colnames = well_parsed[0]\n",
    "data = well_parsed[1:]\n",
    "\n",
    "    #Creating DF:\n",
    "df_web_scrapping = pd.DataFrame(data, columns=colnames)\n",
    "\n",
    "df_web_scrapping['Country(or dependent territory)']=df_web_scrapping['Country(or dependent territory)'].replace(['\\[(.*?)\\]','\\(([^\\)]+)\\)'], ['',''], regex=True)\n",
    "\n",
    "df_web_scrapping.columns = ['Rank', 'country','Population',' % of World Population','Date','Source']\n",
    "\n",
    "#Exporting to CSV: \n",
    "\n",
    "df_web_scrapping.to_csv('/Users/MIGUEL/Desktop/TestProject/df_web_scrapping.csv', index=False)\n",
    "\n",
    "#Import df_web_scrapping, full\n",
    "\n",
    "df_web_scrapping = pd.read_csv('/Users/MIGUEL/Desktop/TestProject/df_web_scrapping.csv')\n",
    "df_total = pd.read_csv('/Users/MIGUEL/Desktop/TestProject/df_total.csv')\n",
    "df_total.country.replace('None', np.nan, regex=True, inplace=True)\n",
    "df_total.country.isnull().sum()\n",
    "df_no_null_values = df_total[df_total.age.isnull()]\n",
    "df_no_null_values.shape\n",
    "df_total.drop(df_total[df_total.country.isnull()].index, inplace = True)\n",
    "df_total.country.isnull().sum()\n",
    "\n",
    "#Merge - df_total,no null values in country col with df_web_scrapping:\n",
    "\n",
    "df_project2 = pd.merge(df_web_scrapping, df_total, on=['country', 'country'])\n",
    "\n",
    "#EXPORTING WEB-SCRAPPING-DF_TOTAL TO LOCAL:\n",
    "\n",
    "df_project2.to_csv('/Users/MIGUEL/Desktop/TestProject/df_project2CLEAN.csv', index=False)\n",
    "\n",
    "#GRAPHICS - STATISTICS - ANALYTICS:\n",
    "    #Extracting data:\n",
    "\n",
    "project1_df = pd.read_csv('/Users/MIGUEL/Desktop/TestProject/df_total.csv')\n",
    "project2_df = pd.read_csv('/Users/MIGUEL/Desktop/TestProject/df_project2CLEAN.csv')\n",
    "\n",
    "    #Checking Outliers: \n",
    "\n",
    "stats = project1_df.describe().T\n",
    "stats['IQR'] = stats['75%'] - stats['25%']\n",
    "stats\n",
    "\n",
    "outliers = pd.DataFrame(columns=project1_df.columns)\n",
    "\n",
    "for col in stats.index:\n",
    "    iqr = stats.at[col,'IQR']\n",
    "    cutoff = iqr * 1.5\n",
    "    lower = stats.at[col,'25%'] - cutoff\n",
    "    upper = stats.at[col,'75%'] + cutoff\n",
    "    results = project1_df[(project1_df[col] < lower) | \n",
    "                   (project1_df[col] > upper)].copy()\n",
    "    results['Outlier'] = col\n",
    "    outliers = outliers.append(results)\n",
    "    'sort=False'\n",
    "\n",
    "outliers\n",
    "\n",
    "#Graphic 1: worth BUSD - full dataframe\n",
    "graphic_1 = project1_df['worth BUSD'].hist(bins=100, figsize=(16,8))\n",
    "graphic_1\n",
    "\n",
    "plt.savefig(\"worth BUSD deviation.png\", bbox_inches='tight')\n",
    "\n",
    "#Graphic 2: wortChange millions USD - full dataframe\n",
    "graphic_2 = project1_df[' worthChange millions USD'].hist(bins=10, figsize=(16,8))\n",
    "graphic_2\n",
    "\n",
    "plt.savefig(\"worthChange millions USD\", bbox_inches='tight')\n",
    "\n",
    "#Graphic 3: worth BUSD - outliers dataframe \n",
    "graphic_3 = outliers['worth BUSD'].hist(bins=10, figsize=(16,8))\n",
    "graphic_3\n",
    "\n",
    "plt.savefig(\"worth BUSD - outliers\", bbox_inches='tight')\n",
    "\n",
    "#Graphic 4: wortChange millions USD - dataframe outliers\n",
    "graphic_4 = outliers[' worthChange millions USD'].hist(bins=10, figsize=(16,8))\n",
    "graphic_4\n",
    "\n",
    "plt.savefig(\"worthChange millions USD - outliers\", bbox_inches='tight')\n",
    "\n",
    "#Graphic 5: Scattter position - worth\n",
    "my_plot = project1_df.plot(\"position\", \"worth BUSD\", kind=\"scatter\")\n",
    "\n",
    "plt.savefig(\"scatter position - worth\") \n",
    "\n",
    "#Graphic 6: Scatter position - worthChange \n",
    "my_plot2 = project1_df.plot(\"position\", \" worthChange millions USD\", kind=\"scatter\")\n",
    "\n",
    "plt.savefig(\"scatter position-worthchange\")\n",
    "\n",
    "#Wealth comparison between genders\n",
    "    #Stadistics\n",
    "\n",
    "wealth_comparison = project1_df.groupby(['gender','worth BUSD']).agg(['count', 'mean'])\n",
    "wealth_comparison\n",
    "\n",
    "    #Graphic7\n",
    "\n",
    "fig = plt.figure(figsize=(30,10))\n",
    "project1_df.gender[project1_df.position].value_counts(normalize = True).plot(kind='barh', alpha=0.5)\n",
    "plt.title('Wealth comparison between genders')\n",
    "\n",
    "plt.savefig(\"Wealth comparison between genders\") \n",
    "\n",
    "#Wealth comparison between countries \n",
    "    #Stadistics\n",
    "\n",
    "wealth_comparison = project2_df.groupby(['country','worth BUSD']).agg(['count', 'mean'])\n",
    "\n",
    "    #Graphic8\n",
    "\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "project2_df.country[project1_df.position].value_counts(normalize = True).plot(kind='barh', alpha=0.5)\n",
    "plt.title('Wealth comparison between countries')\n",
    "\n",
    "plt.savefig(\"Wealth comparison between countries\") \n",
    "\n",
    "#Outliers - Project2_df\n",
    "\n",
    "stats2 = project2_df.describe().T\n",
    "stats['IQR'] = stats['75%'] - stats['25%']\n",
    "stats2\n",
    "\n",
    "outliers2 = pd.DataFrame(columns=project1_df.columns)\n",
    "\n",
    "for col in stats.index:\n",
    "    iqr = stats.at[col,'IQR']\n",
    "    cutoff = iqr * 1.5\n",
    "    lower = stats.at[col,'25%'] - cutoff\n",
    "    upper = stats.at[col,'75%'] + cutoff\n",
    "    results = project2_df[(project2_df[col] < lower) | \n",
    "                   (project2_df[col] > upper)].copy()\n",
    "    results['Outliers2'] = col\n",
    "    outliers2 = outliers2.append(results)\n",
    "    'sort=False'\n",
    "\n",
    "outliers2\n",
    "\n",
    "#Graphic9: \n",
    "\n",
    "my_plot2 = project2_df.plot(\"position\", \" worthChange millions USD\", kind=\"scatter\")\n",
    "\n",
    "plt.savefig(\"scatter-outliers-scrapping\")\n",
    "print('pollas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
