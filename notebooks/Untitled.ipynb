{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "######notas:\n",
    "######Hay que renombrar las variables para conectar las funciones de import, acquire y las handling:\n",
    "\n",
    "###: Exportadores\n",
    "\n",
    "#Import function:\n",
    "\n",
    "def _import_():\n",
    "    df = sqlite3.connect('/Users/MIGUEL/Desktop/CLAB1/Ironhack-Module-1-Project---Pipelines-/data/raw/Miguel318.db')\n",
    "    df = sqlite3.connect('/Users/MIGUEL/Desktop/CLAB1/Ironhack-Module-1-Project---Pipelines-/data/raw/Miguel318.db')\n",
    "    df = sqlite3.connect('/Users/MIGUEL/Desktop/CLAB1/Ironhack-Module-1-Project---Pipelines-/data/raw/Miguel318.db')\n",
    "\n",
    "    return\n",
    "\n",
    "def _acquire_():\n",
    "    dfBI = pd.read_sql_query(\"SELECT * FROM business_info\", df)\n",
    "    dfRI = pd.read_sql_query(\"SELECT * FROM rank_info\", df)\n",
    "    dfPI = pd.read_sql_query(\"SELECT * FROM personal_info\", df)\n",
    "\n",
    "\n",
    "#EXTRACT PRIMITIVE DATA:\n",
    "\n",
    "#BUSINES INFO\n",
    "\n",
    "    \n",
    "#WRANGLING bussines_info\n",
    "    #drop realTimeWorth - 100% nulls\n",
    "\n",
    "dfBI.drop(['realTimeWorth'], axis='columns', inplace=True)\n",
    "\n",
    "    #eliminating columns that do not add value (Unnamed:0, realTimePosition)\n",
    "dfBI.drop(['Unnamed: 0'], axis='columns', inplace=True)\n",
    "dfBI.drop(['realTimePosition'], axis='columns', inplace=True)\n",
    "\n",
    "dfBI.replace({\"BUSD\": ' '})\n",
    "\n",
    "    #replacement of 'na' values by 0.0 in wortChange column\n",
    "\n",
    "dfBI.worthChange.replace('na', '0.0', regex=True, inplace=True)\n",
    "\n",
    "    #regex - separate numerical values\n",
    "dfBI.worth.replace('[BUSD]+$', '', regex=True, inplace=True)\n",
    "dfBI.worthChange.replace('[millions USD]+$', '', regex=True, inplace=True)\n",
    "\n",
    "    #replacement float values with int\n",
    "dfBI['worth'] = dfBI['worth'].astype('float').astype('int')\n",
    "dfBI['worthChange'] = dfBI['worthChange'].astype('float').astype('int')\n",
    "dfBI['id'] = dfBI['id'].astype('object').astype('int')\n",
    "\n",
    "    #checking the type of values in columns\n",
    "print(dfBI['worthChange'].dtype)\n",
    "print(dfBI['worth'].dtype)\n",
    "print(dfBI['id'].dtype)\n",
    "\n",
    "    #Analyzing worthChange column composition:\n",
    "print(dfBI['worthChange'].value_counts())\n",
    "print(dfBI['worthChange'].describe())\n",
    "\n",
    "#Once the value_counts () and describe () methods have been performed, we can see that the column is composed of 97.59% of 0 values, however we can see that they include very extreme values in minimums and maximums, and since it is a column That refers to the exchange rates I think it is convenient not to eliminate the column for futures and possible analyzes during the project.\n",
    "\n",
    "#I rename columns to indicate the units in which the values are expressed and not to contaminate the dataset.\n",
    "\n",
    "dfBI = dfBI.rename(columns={'worth':'worth BUSD', 'worthChange':' worthChange millions USD'})\n",
    "\n",
    "    #Make sure there are no duplicate items\n",
    "dfBI = dfBI.drop_duplicates()\n",
    "\n",
    "#RESET INDEX\n",
    "\n",
    "dfBI = dfBI.reset_index(drop=True)\n",
    "\n",
    "#Exporting the clean dataset to the data/processed folder\n",
    "\n",
    "###dfBI.to_csv('/Users/MIGUEL/Desktop/CLAB1/Ironhack-Module-1-Project---Pipelines-/data/processed/dfBussinesInfoCLEAN.csv', index=False)\n",
    "\n",
    "\n",
    "#RANK INFO\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Wrangling rank_info\n",
    "    #eliminating columns that do not add value (Unnamed:0)\n",
    "\n",
    "dfRI.drop(['Unnamed: 0'], axis='columns', inplace=True)\n",
    "\n",
    "    #Wrangling - \"position column\"\n",
    "\n",
    "print(dfRI.position.isnull().sum())   #Only 52 NaN values, not proceed delete column\n",
    "\n",
    "dfRI['position'] = dfRI['position'].fillna(0)   #replace NaN values with 0.0\n",
    "dfRI['position'] = dfRI['position'].astype('float').astype('int')  #replacement float values with int\n",
    "\n",
    "\n",
    "#convert all characters to lowercase in column name\n",
    "\n",
    "dfRI = dfRI.apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "\n",
    "#analyzing types of values to see the next cleaning stage\n",
    "     #we can verify that we have duplicate elements so we must eliminate them but taking care that we eliminate the correct one and that it contributes less value to the dataframe. \n",
    "\n",
    "    #changing object types\n",
    "    \n",
    "dfRI['position'] = dfRI['position'].astype('object').astype('int')\n",
    "dfRI['id'] = dfRI['id'].astype('object').astype('int')\n",
    "\n",
    "print(dfRI['position'].dtype)\n",
    "print(dfRI['id'].dtype)\n",
    "\n",
    "#I delete the rows that have a value of 0 in the position column, they do not add value to the analysis and thus the size of the table is matched with that of Bussines_info\n",
    "dfRI = dfRI.drop(dfRI[dfRI['position']==0].index)\n",
    "\n",
    "#RESET INDEX\n",
    "dfRI = dfRI.reset_index(drop=True)\n",
    "\n",
    "#Exporting the clean dataset to the data/processed folder\n",
    "\n",
    "###dfRI.to_csv('/Users/MIGUEL/Desktop/CLAB1/Ironhack-Module-1-Project---Pipelines-/data/processed/dfrankinfoCLEAN.csv', index=False)\n",
    "\n",
    "\n",
    "#PERSONAL INFO:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Wrangling personal_info\n",
    "    #Drop Unnamed:0 and lastName, I delete lastname column since we already have the full name and surname in rank_info\n",
    "    \n",
    "dfPI.drop(['Unnamed: 0'], axis='columns', inplace=True)\n",
    "dfPI.drop(['lastName'], axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "    #Wrangling gender column\n",
    "    \n",
    "dfPI.gender.replace('[M]+$', 'Male', regex=True, inplace=True)\n",
    "dfPI.gender.replace('[F]+$', 'Female', regex=True, inplace=True)\n",
    "dfPI['gender'] = dfPI['gender'].astype('object').astype('str')\n",
    "#print(dfPI['gender'].value_counts())\n",
    "   \n",
    "    #Wrangling age column\n",
    "        #Correct info in age column: delete \"years old\" and change data types\n",
    "        \n",
    "dfPI.age.replace('[years old]+$', '', regex=True, inplace=True)   \n",
    "dfPI['age'] = dfPI['age'].fillna(0)   #replace NaN values with 0.0\n",
    "dfPI['age'] = dfPI['age'].astype('float').astype('int') \n",
    "#print(dfPI['age'].value_counts())    \n",
    "#print(dfPI['age'].dtype)  \n",
    "\n",
    "#Checking Types: \n",
    "\n",
    "#print(dfPI['id'].dtype) \n",
    "#print(dfPI['age'].dtype)\n",
    "\n",
    "    #Datetime - preparing \n",
    "\n",
    "now = datetime.now()\n",
    "now.year\n",
    "\n",
    "    #Checking Outliers: \n",
    "\n",
    "stats = dfPI.describe().T\n",
    "stats['IQR'] = stats['75%'] - stats['25%']\n",
    "stats\n",
    "\n",
    "outliers = pd.DataFrame(columns=dfPI.columns)\n",
    "\n",
    "for col in stats.index:\n",
    "    iqr = stats.at[col,'IQR']\n",
    "    cutoff = iqr * 1.5\n",
    "    lower = stats.at[col,'25%'] - cutoff\n",
    "    upper = stats.at[col,'75%'] + cutoff\n",
    "    results = dfPI[(dfPI[col] < lower) | \n",
    "                   (dfPI[col] > upper)].copy()\n",
    "    results['Outlier'] = col\n",
    "    outliers = outliers.append(results)\n",
    "    'sort=False'\n",
    "     \n",
    "dfPI['new_age'] = now.year - outliers['age']\n",
    "\n",
    "dfPI.new_age.fillna(dfPI.age, inplace=True)\n",
    "\n",
    "dfPI['age'] = dfPI['new_age']\n",
    "dfPI.drop(['new_age'], axis='columns', inplace=True)\n",
    "dfPI.age.replace(now.year, 'None', regex=True, inplace=True)\n",
    "\n",
    "\n",
    "#Checking Duplicates\n",
    "\n",
    "dfPI = dfPI.drop_duplicates()\n",
    "\n",
    "#RESET INDEX\n",
    "\n",
    "dfPI = dfPI.reset_index(drop=True)\n",
    "\n",
    "#Exporting the clean dataset to the data/processed folder\n",
    "\n",
    "###dfPI.to_csv('/Users/MIGUEL/Desktop/CLAB1/Ironhack-Module-1-Project---Pipelines-/data/processed/dfPersonalInfoCLEAN.csv', index=False)\n",
    "  \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
